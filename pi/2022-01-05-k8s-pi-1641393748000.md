---
title: "Raspberry Pi No More Dust" Issue 14 Building a k8s Cluster with Raspberry Pi 4B
categories:
- Raspberry Pi No More Dust / Use Pi
---

k8s is a server cluster management tool launched by Google, open-source and free, with powerful features that can create a miracle of one person managing a server cluster.

k8s has a strong versatility, it is a set of standard operation and maintenance strategies, as long as the program is deployed to the server, the stability of the program needs to be considered. With k8s's elastic scaling and multi-host backup strategy, even if some servers physically crash or are attacked by hackers with DDOS, it can automatically respond through built-in strategies.

k8s is open-sourced by Google, and Google itself is using this solution, so we can get continuous, stable technical support and version iteration for free.

k8s is a commercial-grade complete solution, and if you want to step into the professional operation and maintenance field and get a sustenance operation and maintenance job, you also need to be familiar with k8s, a tool that can be called an industry benchmark.

This blog post records the entire process of zhaoolee using Raspberry Pi to build a k8s cluster. If you are interested in the Raspberry Pi k8s cluster, this blog post will be very helpful to you.

First, connect the Raspberry Pi to the same local area network environment. For stability, it is best to connect the router to the Raspberry Pi with a network cable. To avoid the hassle of downloading various dependency packages, the router needs to support scientific Internet access~

The three Raspberry Pi 4Bs used in this article are all 8GB versions, and the image chosen is Ubuntu20.04. If you have any questions about flashing the image to Raspberry Pi, click on the previous [“Raspberry Pi No More Dust” Flash Ubuntu Server 20.04, Bind Public Domain Name, Provide HTTP Service to the Public Network, SSH Login Service https://v2fy.com/p/2021-10-01-pi-server-1633066843000/](https://v2fy.com/p/2021-10-01-pi-server-1633066843000/)

The installed K8s version is v1.23.1

## First, on the three Raspberry Pis running Ubuntu 20.04, install the network tools package
```
sudo apt install net-tools -y
```

## Set a fixed IP for the three Raspberry Pis

You can complete the setup in the web interface of the router by **binding the Raspberry Pi MAC address with the IP**

![Bind MAC address with IP](https://cdn.fangyuanxiaozhan.com/assets/1641393776473aXXap1DB.png)

You can also set a static IP directly on the Raspberry Pi, refer to the tutorial [A concise tutorial for setting a static IP for Ubuntu 20.04 (as simple as putting an elephant in the refrigerator) https://v2fy.com/p/2022-01-01-ip-1641016585000/](https://v2fy.com/p/2022-01-01-ip-1641016585000/)

## Set the hostname using hostnamectl

My router allocated `192.168.50.10`, `192.168.50.20`, `192.168.50.30` to the three Raspberry Pis respectively, and these IPs will be mentioned repeatedly later in the content. If your IP is different from mine, please replace it accordingly.

On the master host with IP `192.168.50.10`, execute

```
hostnamectl set-hostname master
```
![Execute hostnamectl set-hostname](https://cdn.fangyuanxiaozhan.com/assets/16413937764640hbnb7Ws.png)

On node1 host with IP `192.168.50.20`, execute
```
hostnamectl set-hostname node1
```
On node2 host with IP `192.168.50.30`, execute
```
hostnamectl set-hostname node2
```
After setting up, you can view the local machine information with the following command

```
hostnamectl status
```

![Local machine information](https://cdn.fangyuanxiaozhan.com/assets/1641393776455fiFxRtkd.png)

If your shell terminal displays the hostname, you can conveniently distinguish it by the hostname

![Distinguish by hostname](https://cdn.fangyuanxiaozhan.com/assets/1641393776469fKSynTTW.png)

## Modify the host file and create aliases

Add the following configuration in `/etc/hosts` inside the three Raspberry Pis

```
192.168.50.10 master
192.168.50.20 node1
192.168.50.30 node2
```

Ubuntu 20.04 has abandoned SELinux, so we don't need to deal with SELinux settings.

K8s V1.22 version has started to support the use of swap, we don't need to turn off swap memory either.

## To ensure communication between master and nodes, we need to disable the Raspberry Pi firewall

ufw, or Uncomplicated Firewall, is an interface to iptables, providing an easy-to-use interface for beginners unfamiliar with firewall concepts, while supporting both IPv4 and IPv6, widely popular. Ubuntu 20.04 comes with the firewall management tool ufw by default, we can execute the following commands on the three Raspberry Pis to disable the firewall.

```
# Disable the firewall
sudo ufw disable
# Check the firewall status
sudo ufw status
```

![Disable the firewall](https://cdn.fangyuanxiaozhan.com/assets/16413937765156F6mX4aG.png)

Raspberry Pis are usually on internal networks and not prone to attack. If the machine is on an external network, it is recommended to only open the necessary ports.

For reference on ports to be opened: https://kubernetes.io/docs/reference/ports-and-protocols/

## Install Docker

Run the following commands on each of the three Raspberry Pis to complete the installation of Docker

```
sudo apt update

sudo apt install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release -y

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt update

sudo apt install docker-ce=5:20.10.8~3-0~ubuntu-focal docker-ce-cli=5:20.10.9~3-0~ubuntu-focal containerd.io=1.4.11-1 -y

docker -v
```

```
![docker](https://cdn.fangyuanxiaozhan.com/assets/1641393776552f0EzHyxB.png)

## Installing k8s

- Install kubectl, kubelet, and kubeadm on three Raspberry Pis

```
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl

sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubectl kubelet kubeadm
```

- Check if kubectl is installed successfully

```
kubectl version --client
```

![check kubectl](https://cdn.fangyuanxiaozhan.com/assets/1641393776575Z5WhZXQn.png)

- Check if kubelet is installed successfully

```
kubelet --version
```

![check kubelet](https://cdn.fangyuanxiaozhan.com/assets/1641393776698xGXYBeDF.png)

- Check if kubeadm is installed successfully

```
kubeadm version
```

![check kubeadm](https://cdn.fangyuanxiaozhan.com/assets/1641393776753sWQxbssb.png)

## Run the following commands on three Raspberry Pis to ensure kubelet and docker are started and set to start on boot

```
sudo systemctl enable kubelet
sudo systemctl start kubelet
sudo systemctl enable docker
sudo systemctl start docker
```

## Modify the docker configuration

```
sudo chmod 777 -R /opt/
cd /opt
# Kubernetes officially recommends using systemd as the cgroupdriver for Docker, otherwise kubelet won't start
cat <<EOF > daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}
EOF
sudo mv daemon.json /etc/docker/

# Restart to take effect
sudo systemctl daemon-reload
sudo systemctl restart docker
```

## Modify the Raspberry Pi's configuration and reboot

```
sudo vim /boot/firmware/cmdline.txt
```

![addition modification](https://cdn.fangyuanxiaozhan.com/assets/164139377680245wcPFyD.png)

```
cgroup_enable=memory cgroup_memory=1
```

After the modification is complete, reboot the Raspberry Pi

```
reboot
```

## Initialize the cluster on the master node

```
sudo kubeadm init --pod-network-cidr=10.244.0.0/16
```

> Note that you should append the `--pod-network-cidr=10.244.0.0/16` parameter

![get token text](https://cdn.fangyuanxiaozhan.com/assets/1641393777034NYFESb5G.png)

Keep the final token text safe as it is needed for joining worker nodes to the master
```
kubeadm join 192.168.50.10:6443 --token tn3*********9f7  --discovery-token-ca-cert-hash sha256:3862***46739303********94
```

- Copy the kubeadm authorization file to the user's home directory so that kubectl can access the cluster

```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

The content of the final authorization file should look like the format shown in the following image

![authorization file](https://cdn.fangyuanxiaozhan.com/assets/1641393777124ZHKQ4MZE.png)

- Install a network plugin on the master node to facilitate communication for subsequent node connections

```
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

- After the plugin installation, wait for all nodes to be Ready

```
kuberctl get nodes
```

![install network plugin, wait for master node Ready](https://cdn.fangyuanxiaozhan.com/assets/1641393777259xTJdYSTE.png)

## Run the following commands on node1 and node2 to join them to the master node

```
sudo kubeadm join 192.168.50.10:6443 --token tn3*********9f7  --discovery-token-ca-cert-hash sha256:3862***46739303********94
```

The above command includes token parameters generated by the master node when running `sudo kubeadm init`. If forgotten, you can get them again by running `sudo kubeadm token create --print-join-command` on the master node.

- On the master node, run `kubectl get nodes` to check the status of all nodes. When all nodes are Ready, you are all set!

![](https://cdn.fangyuanxiaozhan.com/assets/16413937773940cPRebFP.png)

## Install Kuboard

```
mkdir ~/kuboard-data
sudo docker run -d --restart=unless-stopped --name=kuboard -p 30080:80/tcp -p 10081:10081/tcp -e KUBOARD_ENDPOINT="http://192.168.50.10:30080" -e KUBOARD_AGENT_SERVER_TCP_PORT="10081" -v ~/kuboard-data:/data eipwork/kuboard:v3
```
Access http://192.168.50.10:30080 to visit Kuboard

Login username: `admin`
Login password: `Kuboard123`

![Kuboard](https://cdn.fangyuanxiaozhan.com/assets/1641393777591E2Bt8mwC.png)

- Add a cluster

![Add a cluster](https://cdn.fangyuanxiaozhan.com/assets/1641393777813fAS2Jkah.png)

- Select the .kubeconfig method to import the cluster

![Import the cluster](https://cdn.fangyuanxiaozhan.com/assets/1641393778019FK8eyhBR.png)

- Retrieve information from ~/.kube/config

```
cat ~/.kube/config
```

Paste the text information of ~/.kube/config into the page

![Import the cluster](https://cdn.fangyuanxiaozhan.com/assets/1641393778172bdaFHw81.png)

Import successful

![Import successful](https://cdn.fangyuanxiaozhan.com/assets/1641393778319thTEPNxa.png)

All namespace and node information at a glance

![Information at a glance](https://cdn.fangyuanxiaozhan.com/assets/16413937788883RhtA8kN.png)

## Create service

![Create Service](https://cdn.fangyuanxiaozhan.com/assets/1641393779087d3732hQ6.png)


```
apiVersion: apps/v1
kind: Deployment
metadata:
  # Deployment name
  name: pi-k8s-test
  namespace: ingress-nginx
spec:
  replicas: 2
  # Used to find associated Pods, only matches if all labels match
  selector:
    matchLabels:
      app: pi-k8s-test
  # Defines Pod data
  template:
    metadata:
      labels:
        app: pi-k8s-test
    spec:
      # Define containers, can be multiple
      containers:
      - name: pi-k8s-test # Container name
        image: zhaoolee/pi-k8s-test:001 # Image

---
apiVersion: v1
kind: Service
metadata:
  name: pi-k8s-test
  namespace: ingress-nginx
spec:
  selector:
    app: pi-k8s-test
  type: NodePort
  ports:
    - port: 3000        # Port of this Service
      targetPort: 3000  # Container port
```

From the yaml text above, we can see that we used the image zhaoolee/pi-k8s-test:001 to create two pods (a pod can accommodate N containers produced by running images), and these two pods will be automatically scheduled to different nodes by k8s, with one each on node1 and node2.

![Different nodes](https://cdn.fangyuanxiaozhan.com/assets/1641393779247ABJaxaAC.png)

The second half of the yaml file creates a service, which is the parent of pods. We can access the pods through the 3000 port exposed by the service. A service is also an atomic level service, we can create a large number of services to deal with different scenarios.

However, it is troublesome to manage a large number of services and the occupied ports are also messy. We need something like an Nginx gateway to uniformly receive external requests and then distribute requests to the corresponding services according to the rules set in Nginx. In k8s, this part is referred to as ingress, and ingress has a version developed based on nginx, known as NGINX Ingress Controller. Below I will start to configure and install NGINX Ingress Controller.

## Install helm

```
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

This helm can help us conveniently install NGINX Ingress Controller and freeload many other people's existing service configurations later.

## Install NGINX Ingress Controller

```
helm upgrade --install ingress-nginx ingress-nginx --repo https://kubernetes.github.io/ingress-nginx  --namespace ingress-nginx --create-namespace
```

Reference URL https://kubernetes.github.io/ingress-nginx/deploy/#quick-start

Similar to Nginx, the NGINX Ingress Controller needs to be configured with rules to forward requests according to our requirements. Below we configure a simple rule.

## Add rules for ingress

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress
  namespace: ingress-nginx
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          - backend:
              service:
                name: pi-k8s-test
                port:
                  number: 3000
            path: /
            pathType: ImplementationSpecific
```

From the configuration file above, we can create it directly on the page via Kuboard using YAML. The rule it configures is to send all requests targeting the root path `/` to the 3000 port of the pi-k8s-test service.

If there is an error stating "Internal error occurred: failed calling webhook 'validate.nginx.ingress.kubernetes.io'," then

```
kubectl get validatingwebhookconfigurations
kubectl delete -A ValidatingWebhookConfiguration ingress-nginx-admission
```
Although an ingress is also a service, it is a special one as it requires an IP at the level of the Raspberry Pi to operate (in the format `192.168.50.*`), and ingress is known as a type of service called loadbalancer.

However, Kubernetes itself does not provide support for the loadbalancer type, so we need to install an open-source software named MetalLB to get Kubernetes to support the loadbalancer type. Without installing MetalLB, services of the loadbalancer type can only remain in the pending state.

## Installing MetalLB

First, enable the strictARP option.

```
kubectl edit configmap -n kube-system kube-proxy
```

After entering the above command, you will enter vim editor mode. We change the configuration from `strictARP: false` to `strictARP: true`.

```
strictARP: true
```

- Create a namespace dedicated to MetalLB.

```
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/namespace.yaml
```
- Deploy MetalLB.

```
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/metallb.yaml
```

- Create the memberlist secret, which is used to encrypt the communication between speakers.

```
kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)"
```

- Create a ConfigMap through Kuboard.

![Import](https://cdn.fangyuanxiaozhan.com/assets/16413937794445sA65aGA.png)

```
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    address-pools:
    - name: default
      protocol: layer2
      addresses:
      - 192.168.50.240-192.168.50.250
```

Note the last line of the addresses configuration. The router above my Raspberry Pi is in the `192.168.50.*` segment, so the configuration is `192.168.50.240-192.168.50.250`. Please change this according to your own router's configuration as needed.

- Check the LoadBalancer type ingress-nginx-controller.

```
kubectl get svc -A
```
![Allocated to IP](https://cdn.fangyuanxiaozhan.com/assets/1641393779523QWaAWFEY.png)

The IP assigned to `ingress-nginx-controller` is `192.168.50.240`.

We can access `http://192.168.50.240` from a computer on the LAN.

![Access](https://cdn.fangyuanxiaozhan.com/assets/16413937796187rJDCih7.png)

Accessing 192.168.50.240 is equivalent to accessing the ingress-nginx-controller. The ingress-nginx-controller will forward our requests, according to the rules, to the services we established previously. The services will automatically forward requests to two pods for processing. Multiple pods themselves run on different nodes (on different Raspberry Pis). Even if a node goes down, it can still provide services stably to the outside world.

If the volume of requests we receive increases, we can handle the traffic by increasing the number of pods or adding more Raspberry Pis (nodes).

Reference: https://www.bboy.app/2021/01/11/metallb%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8/

## How to quickly change images?

Previously, we used the zhaoolee/pi-k8s-test:001 image. If you want to switch to the zhaoolee/pi-k8s-test:002 image, you just need to open Kuboard and change the image version.

![Update image](https://cdn.fangyuanxiaozhan.com/assets/1641393779960mS1xHxrd.png)

The Kubernetes cluster will automatically pull the image and complete the update.

- Successful content update.

![Update successful](https://cdn.fangyuanxiaozhan.com/assets/1641393780302WnGfD7y5.png)

## Expose the Raspberry Pi service to the internet

Through the previous steps, we have made 192.168.50.240 the entrance to our Kubernetes cluster. Next, we simply use FRP to penetrate 192.168.50.240 to the public internet domain k8s.v2fy.com, allowing external internet access to services provided by the Raspberry Pi cluster.

- Final effect display

![k8s.v2fy.com](https://cdn.fangyuanxiaozhan.com/assets/1641470734371r4Ka16Sk.png)

192.168.50.10 is responsible for running the master, and it cannot access our load balancer IP 192.168.50.240. However, the machines on node1 (192.168.50.20) and node2 (192.168.50.20) can access the load balancer IP successfully.

We choose to start the FRP client service on the Raspberry Pi where node1 is located.

- `frpc.ini` configuration file:

```
[common]
server_addr = 120.76.136.220
server_port = 7000
token = '********'
log_file = './frpc.log'

[pi-k8s]
type = tcp
local_ip = 192.168.50.240
local_port = 80
remote_port = 9666
```

The role of the configuration file is to tunnel the local network `192.168.50.240:80` to the public network `120.76.136.220:9666`.

For FRP installation and usage instructions, please refer to ["Raspberry Pi Dust-Free" flashing Ubuntu Server 20.04, binding to a public domain, providing HTTP service to the public internet, SSH login service https://v2fy.com/p/2021-10-01-pi-server-1633066843000/](https://v2fy.com/p/2021-10-01-pi-server-1633066843000/).

- Resolve your own domain name (such as k8s.v2fy.com) to the public server IP (such as 120.76.136.220).
Then the public server Nginx proxies k8s.v2fy.com, forwarding all requests aimed at the 80 and 443 ports of k8s.v2fy.com to port 9666.

Nginx reference configuration file `/etc/nginx/conf.d/k8s.v2fy.com.conf`

```
upstream k8s_v2fy_com { server 127.0.0.1:9666; }

server {
    server_name      k8s.v2fy.com;
    listen       80;
    listen       [::]:80;
    rewrite ^(.*)$ https://$host$1 permanent;
}

server {
    listen       443 ssl http2;
    listen       [::]:443 ssl http2;
    server_name  k8s.v2fy.com;

    location / {
        proxy_pass http://k8s_v2fy_com;
        proxy_set_header Host $host:443;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    ssl_certificate "/etc/nginx/ssl/k8s.v2fy.com/fullchain.cer";
    ssl_certificate_key "/etc/nginx/ssl/k8s.v2fy.com/k8s.v2fy.com.key";
    ssl_session_cache shared:SSL:1m;
    ssl_session_timeout  10m;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;

    # Load configuration files for the default server block.
    include /etc/nginx/default.d/*.conf;

    error_page 404 /404.html;
        location = /40x.html {
    }

    error_page 500 502 503 504 /50x.html;
        location = /50x.html {
    }
}
```

- How to obtain automatically renewed https certificates?

Please refer to [Zero Dependency! Use acme.sh to set up nginx multiple https certificates automatic update, unlimited renewal of https certificates https://v2fy.com/p/2021-06-27-nginx-https-1624774964000/](https://v2fy.com/p/2021-06-27-nginx-https-1624774964000/)

After installing the certificate, remember to restart Nginx

```
sudo nginx -t
sudo systemctl restart nginx
```

- Finally, we can access our internal k8s services through https://k8s.v2fy.com

![Small animal picture](https://cdn.fangyuanxiaozhan.com/assets/1641473987496kAiK80HC.png)

![Chair](https://cdn.fangyuanxiaozhan.com/assets/1641474036704Q1EWpXyb.png)

![Winter Day](https://cdn.fangyuanxiaozhan.com/assets/1641474411824eYeN8Aa5.png)

## Summary

If you're just looking to learn k8s technology and not set up a cluster, you can completely use minikube to study, Ubuntu 20.04 test water k8s single-machine minikube deployment record https://v2fy.com/p/2021-07-26-k8s-1627292526000/

Since New Year's Day 2022, I've been fiddling with building k8s on a bare Raspberry Pi, and as of the time of this writing, it has been 5 days. K8s is indeed an enticing technology, and technology enthusiasts can build their own cluster and run their services smoothly after a few days of learning. The design philosophy of the k8s cluster can also be regarded as an excellent textbook. Through layer-by-layer abstraction and separation, the scheduling of various service pods becomes clear, problem tracing becomes simple, and managing numerous services is also simplified.

In 2022, speculators are still thinking about issuing various coins to shear the leeks, mining consumes a large amount of electricity, just for an irrelevant string. Even those who don't understand computers can shout "distributed" a couple of times and become a qualified leek. The cycle continues, but the k8s system, which truly manages server clusters through distribution, is overlooked. After all, the steady value produced by stable systems is not understood by most people. The famous artist Mr. Sun Yuchen wanders with his ancestral million-to-stir up hype. Chasing trends earns quicker than understanding distributed systems, but k8s technology, which can enhance productivity and is well-learned, doesn't require frequent job hopping and can also fetch a good price. Even in mining, those who use k8s clusters to manage mining machines in bulk can deal a dimensionality reduction strike to those mining with several Windows machines.
